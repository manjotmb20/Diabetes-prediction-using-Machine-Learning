# -*- coding: utf-8 -*-
"""fdiabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yS0_SEjFqA1Fsk1OQ_Pq2u19_nqk925G
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier 
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold
from sklearn.model_selection import StratifiedKFold

from sklearn.model_selection import GridSearchCV

from sklearn.feature_selection import RFECV
import lightgbm as lgb

import xgboost as xgb

diabetes=pd.read_csv("diabetes.csv")

"""Feature labels description-: 
preg-: Pregnancies
plas-: Glucose
pres-: BloodPressure
skin-: SkinThickness
insu-: Insulin
mass-: BMI
pedi-: DiabetesPedigreeFunction
age-:  Age
"""

diabetes.head()

"""Removing outlier from skinthickness"""

max_skinthickness=diabetes.skin.max()
diabetes=diabetes[diabetes.skin!=max_skinthickness]

"""Replacing Zero values in Pressure,SkinThickness,Insulin,BMI with mean"""

def replace_zero(df,field,target):
  mean=df.loc[df[field]!=0,[field,target]].groupby(target).mean()
  diabetes.loc[(df[field]==0)&(df[target]==0),field]=mean.iloc[0][0]
  diabetes.loc[(df[field]==0)&(df[target]==1),field]=mean.iloc[1][0]

for col in ['plas','pres','skin','insu','mass']:
  replace_zero(diabetes,col,'class')

diabetes.groupby('class').size()

diabetes.isnull().sum()

diabetes[diabetes.mass==0].shape

diabetes=diabetes[(diabetes.pres!=0)&(diabetes.mass!=0)&(diabetes.plas!=0)]

feature_names=['preg','plas','pres','skin','insu','mass','pedi','age']
X=diabetes[feature_names]
y=diabetes['class']

y.head()

models=[]
models.append(('KNN',KNeighborsClassifier()))
models.append(('SVC',SVC()))
models.append(('LR',LogisticRegression()))
models.append(('DT',DecisionTreeClassifier()))
models.append(('GNB',GaussianNB()))
models.append(('RF',RandomForestClassifier()))
models.append(('GB',GradientBoostingClassifier()))

X_train, X_test, y_train, y_test=train_test_split(X,y,stratify=diabetes['class'],random_state=0)

len(X_test)

names=[]
scores=[]

for name, model in models:
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  scores.append(accuracy_score(y_test,y_pred))
  names.append(name)

tr_split=pd.DataFrame({'Name': names, 'Score': scores})
print(tr_split)

strat_k_fold = StratifiedKFold(n_splits=10, random_state=10)
names=[]
scores=[]

for name, model in models:
  score=cross_val_score(model,X,y,cv=strat_k_fold,scoring='accuracy').mean()
  names.append(name)
  scores.append(score)

kf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})
print(kf_cross_val)



"""GRID SEARCH on XGB Parameters-: As from the above algorithms we see that Gradient Boosting algorithm performed well with 89% accuracy, so we will further explore XGboost Algorithm."""

target='class'
predictors=['preg','plas','pres','skin','insu','mass','pedi','age']
param_test1 = {
 'max_depth':range(3,10,2),
 'min_child_weight':range(1,6,2)
}
gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,
 min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,
 objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), 
 param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)
gsearch1.fit(diabetes[predictors],diabetes[target])

"""Implementing XGBoost Classifier"""

clf3=xgb.XGBClassifier(learning_rate=0.1,n_estimators=200,max_depth=5,min_child_weight=5,gamma=0,subsample=0.8,colsample_bytree=0.8,reg_alpha=0.005,objective='binary:logistic',n_thread=4,scale_pos_weight=1)
clf3.fit(X_train,y_train)
y_pred=clf3.predict(X_test)
print("Final Best Accuracy-: {}%".format(accuracy_score(y_test,y_pred)*100))



